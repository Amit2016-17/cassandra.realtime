[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/javadsl/CassandraSink.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.javadsl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport java.util.concurrent.CompletionStage[0m
[0m[[0m[0mdebug[0m] [0m[0mimport java.util.function.BiFunction[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.Done[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.ApiMayChange[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.scaladsl.{CassandraSink => ScalaCSink}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.javadsl.Sink[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.datastax.driver.core.{BoundStatement, PreparedStatement, Session}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.compat.java8.FutureConverters._[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mobject CassandraSink {[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  def create[T](parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m                statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m                statementBinder: BiFunction[T, PreparedStatement, BoundStatement],[0m
[0m[[0m[0mdebug[0m] [0m[0m                session: Session): Sink[T, CompletionStage[Done]] = {[0m
[0m[[0m[0mdebug[0m] [0m[0m    val sink =[0m
[0m[[0m[0mdebug[0m] [0m[0m      ScalaCSink.apply[T](parallelism, statement, (t, p) => statementBinder.apply(t, p))(session)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m    sink.mapMaterializedValue(_.toJava).asJava[0m
[0m[[0m[0mdebug[0m] [0m[0m  }[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/javadsl/CassandraFlow.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.javadsl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport java.util.function.BiFunction[0m
[0m[[0m[0mdebug[0m] [0m[0mimport java.util.function.Function[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.NotUsed[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.ApiMayChange[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.CassandraBatchSettings[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.datastax.driver.core.{BoundStatement, PreparedStatement, Session}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.scaladsl.{CassandraFlow => ScalaCFlow}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.javadsl.Flow[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.ExecutionContext[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mobject CassandraFlow {[0m
[0m[[0m[0mdebug[0m] [0m[0m  def createWithPassThrough[T](parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m                               statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m                               statementBinder: BiFunction[T, PreparedStatement, BoundStatement],[0m
[0m[[0m[0mdebug[0m] [0m[0m                               session: Session): Flow[T, T, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    ScalaCFlow[0m
[0m[[0m[0mdebug[0m] [0m[0m      .createWithPassThrough[T](parallelism, statement, (t, p) => statementBinder.apply(t, p))(session)[0m
[0m[[0m[0mdebug[0m] [0m[0m      .asJava[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  @deprecated("use createWithPassThrough without ExecutionContext instead", "0.20")[0m
[0m[[0m[0mdebug[0m] [0m[0m  def createWithPassThrough[T](parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m                               statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m                               statementBinder: BiFunction[T, PreparedStatement, BoundStatement],[0m
[0m[[0m[0mdebug[0m] [0m[0m                               session: Session,[0m
[0m[[0m[0mdebug[0m] [0m[0m                               ignored: ExecutionContext): Flow[T, T, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    ScalaCFlow[0m
[0m[[0m[0mdebug[0m] [0m[0m      .createWithPassThrough[T](parallelism, statement, (t, p) => statementBinder.apply(t, p))(session)[0m
[0m[[0m[0mdebug[0m] [0m[0m      .asJava[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Creates a flow that batches using an unlogged batch. Use this when most of the elements in the stream[0m
[0m[[0m[0mdebug[0m] [0m[0m   * share the same partition key. Cassandra unlogged batches that share the same partition key will only[0m
[0m[[0m[0mdebug[0m] [0m[0m   * resolve to one write internally in Cassandra, boosting write performance.[0m
[0m[[0m[0mdebug[0m] [0m[0m   *[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Be aware that this stage does not preserve the upstream order.[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def createUnloggedBatchWithPassThrough[T, K](parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               statementBinder: BiFunction[T, PreparedStatement, BoundStatement],[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               partitionKey: Function[T, K],[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               settings: CassandraBatchSettings,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               session: Session): Flow[T, T, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    ScalaCFlow[0m
[0m[[0m[0mdebug[0m] [0m[0m      .createUnloggedBatchWithPassThrough[T, K](parallelism,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                statement,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                (t, p) => statementBinder.apply(t, p),[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                t => partitionKey.apply(t),[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                settings)(session)[0m
[0m[[0m[0mdebug[0m] [0m[0m      .asJava[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Creates a flow that batches using an unlogged batch. Use this when most of the elements in the stream[0m
[0m[[0m[0mdebug[0m] [0m[0m   * share the same partition key. Cassandra unlogged batches that share the same partition key will only[0m
[0m[[0m[0mdebug[0m] [0m[0m   * resolve to one write internally in Cassandra, boosting write performance.[0m
[0m[[0m[0mdebug[0m] [0m[0m   *[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Be aware that this stage does not preserve the upstream order.[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  @deprecated("use createUnloggedBatchWithPassThrough without ExecutionContext instead", "0.20")[0m
[0m[[0m[0mdebug[0m] [0m[0m  def createUnloggedBatchWithPassThrough[T, K](parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               statementBinder: BiFunction[T, PreparedStatement, BoundStatement],[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               partitionKey: Function[T, K],[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               settings: CassandraBatchSettings,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               session: Session,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                               ignored: ExecutionContext): Flow[T, T, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    ScalaCFlow[0m
[0m[[0m[0mdebug[0m] [0m[0m      .createUnloggedBatchWithPassThrough[T, K](parallelism,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                statement,[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                (t, p) => statementBinder.apply(t, p),[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                t => partitionKey.apply(t),[0m
[0m[[0m[0mdebug[0m] [0m[0m                                                settings)(session)[0m
[0m[[0m[0mdebug[0m] [0m[0m      .asJava[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/javadsl/CassandraSource.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.javadsl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport java.util.concurrent.CompletableFuture[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.NotUsed[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.ApiMayChange[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.impl.CassandraSourceStage[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.javadsl.Source[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.datastax.driver.core.{Row, Session, Statement}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.Future[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mobject CassandraSource {[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Java API: creates a [[CassandraSource]] from a given statement.[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def create(stmt: Statement, session: Session): Source[Row, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    akka.stream.javadsl.Source.fromGraph(new CassandraSourceStage(Future.successful(stmt), session))[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Java API: creates a [[CassandraSource]] from the result of a given CompletableFuture.[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def createFromFuture([0m
[0m[[0m[0mdebug[0m] [0m[0m      futStmt: CompletableFuture[Statement],[0m
[0m[[0m[0mdebug[0m] [0m[0m      session: Session[0m
[0m[[0m[0mdebug[0m] [0m[0m  ): Source[Row, NotUsed] = {[0m
[0m[[0m[0mdebug[0m] [0m[0m    import scala.compat.java8.FutureConverters._[0m
[0m[[0m[0mdebug[0m] [0m[0m    akka.stream.javadsl.Source.fromGraph(new CassandraSourceStage(futStmt.toScala, session))[0m
[0m[[0m[0mdebug[0m] [0m[0m  }[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/settings.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.ApiMayChange[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.duration.FiniteDuration[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.duration._[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.util.JavaDurationConverters._[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mfinal class CassandraBatchSettings private (val maxGroupSize: Int, val maxGroupWait: FiniteDuration) {[0m
[0m[[0m[0mdebug[0m] [0m[0m  require([0m
[0m[[0m[0mdebug[0m] [0m[0m    maxGroupSize > 0,[0m
[0m[[0m[0mdebug[0m] [0m[0m    s"Invalid value for maxGroupSize: $maxGroupSize. It should be > 0."[0m
[0m[[0m[0mdebug[0m] [0m[0m  )[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  def withMaxGroupSize(maxGroupSize: Int): CassandraBatchSettings =[0m
[0m[[0m[0mdebug[0m] [0m[0m    copy(maxGroupSize = maxGroupSize)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  def withMaxGroupWait(maxGroupWait: FiniteDuration): CassandraBatchSettings =[0m
[0m[[0m[0mdebug[0m] [0m[0m    copy(maxGroupWait = maxGroupWait)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  def withMaxGroupWait(maxGroupWait: java.time.Duration): CassandraBatchSettings =[0m
[0m[[0m[0mdebug[0m] [0m[0m    copy(maxGroupWait = maxGroupWait.asScala)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  private def copy(maxGroupSize: Int = maxGroupSize, maxGroupWait: FiniteDuration = maxGroupWait) =[0m
[0m[[0m[0mdebug[0m] [0m[0m    new CassandraBatchSettings(maxGroupSize, maxGroupWait)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  override def toString: String =[0m
[0m[[0m[0mdebug[0m] [0m[0m    s"CassandraBatchSettings(maxGroupSize=$maxGroupSize, maxGroupWait=$maxGroupWait)"[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mobject CassandraBatchSettings {[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  def apply(maxGroupSize: Int, maxGroupWait: FiniteDuration): CassandraBatchSettings =[0m
[0m[[0m[0mdebug[0m] [0m[0m    new CassandraBatchSettings(maxGroupSize, maxGroupWait)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Java API[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def create(maxGroupSize: Int, maxGroupWait: java.time.Duration): CassandraBatchSettings =[0m
[0m[[0m[0mdebug[0m] [0m[0m    CassandraBatchSettings(maxGroupSize, maxGroupWait.asScala)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  val default = new CassandraBatchSettings(50, 500.millis)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  def apply(): CassandraBatchSettings = default[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Java API[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def create(): CassandraBatchSettings = default[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/scaladsl/CassandraSink.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.scaladsl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.Done[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.ApiMayChange[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.impl.GuavaFutures._[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.scaladsl.{Flow, Keep, Sink}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.datastax.driver.core.{BoundStatement, PreparedStatement, Session}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.Future[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m/**[0m
[0m[[0m[0mdebug[0m] [0m[0m * Scala API to create Cassandra Sinks.[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mobject CassandraSink {[0m
[0m[[0m[0mdebug[0m] [0m[0m  def apply[T]([0m
[0m[[0m[0mdebug[0m] [0m[0m      parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m      statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m      statementBinder: (T, PreparedStatement) => BoundStatement[0m
[0m[[0m[0mdebug[0m] [0m[0m  )(implicit session: Session): Sink[T, Future[Done]] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    Flow[T][0m
[0m[[0m[0mdebug[0m] [0m[0m      .mapAsyncUnordered(parallelism)(t ⇒ session.executeAsync(statementBinder(t, statement)).asScala())[0m
[0m[[0m[0mdebug[0m] [0m[0m      .toMat(Sink.ignore)(Keep.right)[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/scaladsl/CassandraFlow.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.scaladsl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.NotUsed[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.ApiMayChange[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.dispatch.ExecutionContexts[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.FlowShape[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.CassandraBatchSettings[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.scaladsl.{Flow, GraphDSL}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.datastax.driver.core.{BatchStatement, BoundStatement, PreparedStatement, Session}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.impl.GuavaFutures._[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.collection.JavaConverters._[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m/**[0m
[0m[[0m[0mdebug[0m] [0m[0m * Scala API to create Cassandra flows.[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mobject CassandraFlow {[0m
[0m[[0m[0mdebug[0m] [0m[0m  def createWithPassThrough[T]([0m
[0m[[0m[0mdebug[0m] [0m[0m      parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m      statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m      statementBinder: (T, PreparedStatement) => BoundStatement[0m
[0m[[0m[0mdebug[0m] [0m[0m  )(implicit session: Session): Flow[T, T, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    Flow[T].mapAsync(parallelism)([0m
[0m[[0m[0mdebug[0m] [0m[0m      t ⇒[0m
[0m[[0m[0mdebug[0m] [0m[0m        session[0m
[0m[[0m[0mdebug[0m] [0m[0m          .executeAsync(statementBinder(t, statement))[0m
[0m[[0m[0mdebug[0m] [0m[0m          .asScala()[0m
[0m[[0m[0mdebug[0m] [0m[0m          .map(_ => t)(ExecutionContexts.sameThreadExecutionContext)[0m
[0m[[0m[0mdebug[0m] [0m[0m    )[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Creates a flow that batches using an unlogged batch. Use this when most of the elements in the stream[0m
[0m[[0m[0mdebug[0m] [0m[0m   * share the same partition key. Cassandra unlogged batches that share the same partition key will only[0m
[0m[[0m[0mdebug[0m] [0m[0m   * resolve to one write internally in Cassandra, boosting write performance.[0m
[0m[[0m[0mdebug[0m] [0m[0m   *[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Be aware that this stage does not preserve the upstream order.[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def createUnloggedBatchWithPassThrough[T, K]([0m
[0m[[0m[0mdebug[0m] [0m[0m      parallelism: Int,[0m
[0m[[0m[0mdebug[0m] [0m[0m      statement: PreparedStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m      statementBinder: (T, PreparedStatement) => BoundStatement,[0m
[0m[[0m[0mdebug[0m] [0m[0m      partitionKey: T => K,[0m
[0m[[0m[0mdebug[0m] [0m[0m      settings: CassandraBatchSettings = CassandraBatchSettings()[0m
[0m[[0m[0mdebug[0m] [0m[0m  )(implicit session: Session): Flow[T, T, NotUsed] = {[0m
[0m[[0m[0mdebug[0m] [0m[0m    val graph = GraphDSL.create() { implicit builder =>[0m
[0m[[0m[0mdebug[0m] [0m[0m      import GraphDSL.Implicits._[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m      val groupStage: FlowShape[T, Seq[T]] =[0m
[0m[[0m[0mdebug[0m] [0m[0m        builder.add(Flow[T].groupedWithin(settings.maxGroupSize, settings.maxGroupWait))[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m      val groupByKeyStage: FlowShape[Seq[T], Seq[T]] =[0m
[0m[[0m[0mdebug[0m] [0m[0m        builder.add(Flow[Seq[T]].map(_.groupBy(partitionKey).values.toList).mapConcat(identity))[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m      val batchStatementStage: FlowShape[Seq[T], Seq[T]] = builder.add([0m
[0m[[0m[0mdebug[0m] [0m[0m        Flow[Seq[T]].mapAsyncUnordered(parallelism)([0m
[0m[[0m[0mdebug[0m] [0m[0m          list => {[0m
[0m[[0m[0mdebug[0m] [0m[0m            val boundStatements = list.map(t => statementBinder(t, statement))[0m
[0m[[0m[0mdebug[0m] [0m[0m            val batchStatement = new BatchStatement(BatchStatement.Type.UNLOGGED).addAll(boundStatements.asJava)[0m
[0m[[0m[0mdebug[0m] [0m[0m            session[0m
[0m[[0m[0mdebug[0m] [0m[0m              .executeAsync(batchStatement)[0m
[0m[[0m[0mdebug[0m] [0m[0m              .asScala()[0m
[0m[[0m[0mdebug[0m] [0m[0m              .map(_ => list)(ExecutionContexts.sameThreadExecutionContext)[0m
[0m[[0m[0mdebug[0m] [0m[0m          }[0m
[0m[[0m[0mdebug[0m] [0m[0m        )[0m
[0m[[0m[0mdebug[0m] [0m[0m      )[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m      val flattenResults: FlowShape[Seq[T], T] = builder.add(Flow[Seq[T]].mapConcat(_.toList))[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m      groupStage ~> groupByKeyStage ~> batchStatementStage ~> flattenResults[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m      FlowShape(groupStage.in, flattenResults.out)[0m
[0m[[0m[0mdebug[0m] [0m[0m    }[0m
[0m[[0m[0mdebug[0m] [0m[0m    Flow.fromGraph(graph)[0m
[0m[[0m[0mdebug[0m] [0m[0m  }[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/scaladsl/CassandraSource.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.scaladsl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.NotUsed[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.ApiMayChange[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.alpakka.cassandra.impl.CassandraSourceStage[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.scaladsl.Source[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.datastax.driver.core._[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.Future[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m@ApiMayChange // https://github.com/akka/alpakka/issues/1213[0m
[0m[[0m[0mdebug[0m] [0m[0mobject CassandraSource {[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Scala API: creates a [[CassandraSourceStage]] from a given statement.[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def apply(stmt: Statement)(implicit session: Session): Source[Row, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    Source.fromGraph(new CassandraSourceStage(Future.successful(stmt), session))[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  /**[0m
[0m[[0m[0mdebug[0m] [0m[0m   * Scala API: creates a [[CassandraSourceStage]] from the result of a given Future.[0m
[0m[[0m[0mdebug[0m] [0m[0m   */[0m
[0m[[0m[0mdebug[0m] [0m[0m  def fromFuture(futStmt: Future[Statement])(implicit session: Session): Source[Row, NotUsed] =[0m
[0m[[0m[0mdebug[0m] [0m[0m    Source.fromGraph(new CassandraSourceStage(futStmt, session))[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/impl/GuavaFutures.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.impl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.google.common.util.concurrent.{FutureCallback, Futures, ListenableFuture}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.{Future, Promise}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.util.{Failure, Success, Try}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mprivate[cassandra] object GuavaFutures {[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  def invokeTryCallback[T](listenableFuture: ListenableFuture[T],[0m
[0m[[0m[0mdebug[0m] [0m[0m                           executor: java.util.concurrent.Executor)(callback: Try[T] => Unit): Unit =[0m
[0m[[0m[0mdebug[0m] [0m[0m    Futures.addCallback([0m
[0m[[0m[0mdebug[0m] [0m[0m      listenableFuture,[0m
[0m[[0m[0mdebug[0m] [0m[0m      new FutureCallback[T] {[0m
[0m[[0m[0mdebug[0m] [0m[0m        override def onSuccess(result: T): Unit = callback(Success(result))[0m
[0m[[0m[0mdebug[0m] [0m[0m        override def onFailure(t: Throwable): Unit = callback(Failure(t))[0m
[0m[[0m[0mdebug[0m] [0m[0m      },[0m
[0m[[0m[0mdebug[0m] [0m[0m      executor[0m
[0m[[0m[0mdebug[0m] [0m[0m    )[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  implicit final class GuavaFutureOpts[A](val guavaFut: ListenableFuture[A]) extends AnyVal {[0m
[0m[[0m[0mdebug[0m] [0m[0m    def asScala(): Future[A] = {[0m
[0m[[0m[0mdebug[0m] [0m[0m      val p = Promise[A]()[0m
[0m[[0m[0mdebug[0m] [0m[0m      val callback = new FutureCallback[A] {[0m
[0m[[0m[0mdebug[0m] [0m[0m        override def onSuccess(a: A): Unit = p.success(a)[0m
[0m[[0m[0mdebug[0m] [0m[0m        override def onFailure(err: Throwable): Unit = p.failure(err)[0m
[0m[[0m[0mdebug[0m] [0m[0m      }[0m
[0m[[0m[0mdebug[0m] [0m[0m      Futures.addCallback(guavaFut, callback)[0m
[0m[[0m[0mdebug[0m] [0m[0m      p.future[0m
[0m[[0m[0mdebug[0m] [0m[0m    }[0m
[0m[[0m[0mdebug[0m] [0m[0m  }[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to create/update header for /root/alpakka/cassandra/src/main/scala/akka/stream/alpakka/cassandra/impl/CassandraSourceStage.scala[0m
[0m[[0m[0mdebug[0m] [0m[0mFirst line of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mText of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0m/*[0m
[0m[[0m[0mdebug[0m] [0m[0m * Copyright (C) 2016-2019 Lightbend Inc. <http://www.lightbend.com>[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mpackage akka.stream.alpakka.cassandra.impl[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.annotation.InternalApi[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream._[0m
[0m[[0m[0mdebug[0m] [0m[0mimport akka.stream.stage.{GraphStage, GraphStageLogic, OutHandler}[0m
[0m[[0m[0mdebug[0m] [0m[0mimport com.datastax.driver.core.{ResultSet, Row, Session, Statement}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.concurrent.Future[0m
[0m[[0m[0mdebug[0m] [0m[0mimport scala.util.{Failure, Success, Try}[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m/**[0m
[0m[[0m[0mdebug[0m] [0m[0m * INTERNAL API[0m
[0m[[0m[0mdebug[0m] [0m[0m */[0m
[0m[[0m[0mdebug[0m] [0m[0m@InternalApi private[cassandra] final class CassandraSourceStage(futStmt: Future[Statement], session: Session)[0m
[0m[[0m[0mdebug[0m] [0m[0m    extends GraphStage[SourceShape[Row]] {[0m
[0m[[0m[0mdebug[0m] [0m[0m  val out: Outlet[Row] = Outlet("CassandraSource.out")[0m
[0m[[0m[0mdebug[0m] [0m[0m  override val shape: SourceShape[Row] = SourceShape(out)[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m  override def createLogic(inheritedAttributes: Attributes): GraphStageLogic = new GraphStageLogic(shape) {[0m
[0m[[0m[0mdebug[0m] [0m[0m    var maybeRs = Option.empty[ResultSet][0m
[0m[[0m[0mdebug[0m] [0m[0m    var futFetchedCallback: Try[ResultSet] => Unit = _[0m
[0m[[0m[0mdebug[0m] [0m[0m    var isFetching = true // set to true until prestart's callback will set to false[0m
[0m[[0m[0mdebug[0m] [0m[0m    var minimumPreFetchSize: Int = _[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m    override def preStart(): Unit = {[0m
[0m[[0m[0mdebug[0m] [0m[0m      futFetchedCallback = getAsyncCallback[Try[ResultSet]](tryPushAfterFetch).invoke[0m
[0m[[0m[0mdebug[0m] [0m[0m      val exec = materializer.executionContext[0m
[0m[[0m[0mdebug[0m] [0m[0m      futStmt.foreach { stmt: Statement =>[0m
[0m[[0m[0mdebug[0m] [0m[0m        minimumPreFetchSize = math.max(1, stmt.getFetchSize / 2)[0m
[0m[[0m[0mdebug[0m] [0m[0m        val gFut = session.executeAsync(stmt)[0m
[0m[[0m[0mdebug[0m] [0m[0m        GuavaFutures.invokeTryCallback(gFut, exec)(futFetchedCallback)[0m
[0m[[0m[0mdebug[0m] [0m[0m      }(exec)[0m
[0m[[0m[0mdebug[0m] [0m[0m    }[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m    setHandler([0m
[0m[[0m[0mdebug[0m] [0m[0m      out,[0m
[0m[[0m[0mdebug[0m] [0m[0m      new OutHandler {[0m
[0m[[0m[0mdebug[0m] [0m[0m        override def onPull(): Unit = maybeRs.foreach { rs =>[0m
[0m[[0m[0mdebug[0m] [0m[0m          val currentlyAvailableRows = rs.getAvailableWithoutFetching[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m          if (!isFetching && currentlyAvailableRows < minimumPreFetchSize) {[0m
[0m[[0m[0mdebug[0m] [0m[0m            isFetching = true[0m
[0m[[0m[0mdebug[0m] [0m[0m            // fetch next page[0m
[0m[[0m[0mdebug[0m] [0m[0m            val gFut = rs.fetchMoreResults()[0m
[0m[[0m[0mdebug[0m] [0m[0m            val exec = materializer.executionContext[0m
[0m[[0m[0mdebug[0m] [0m[0m            GuavaFutures.invokeTryCallback(gFut, exec)(futFetchedCallback)[0m
[0m[[0m[0mdebug[0m] [0m[0m          }[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m          if (currentlyAvailableRows > 0)[0m
[0m[[0m[0mdebug[0m] [0m[0m            push(out, rs.one())[0m
[0m[[0m[0mdebug[0m] [0m[0m        }[0m
[0m[[0m[0mdebug[0m] [0m[0m      }[0m
[0m[[0m[0mdebug[0m] [0m[0m    )[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m    private[this] def tryPushAfterFetch(rsOrFailure: Try[ResultSet]): Unit = rsOrFailure match {[0m
[0m[[0m[0mdebug[0m] [0m[0m      case Success(newRs) =>[0m
[0m[[0m[0mdebug[0m] [0m[0m        isFetching = false[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m        val rs = maybeRs.getOrElse {[0m
[0m[[0m[0mdebug[0m] [0m[0m          maybeRs = Some(newRs)[0m
[0m[[0m[0mdebug[0m] [0m[0m          newRs[0m
[0m[[0m[0mdebug[0m] [0m[0m        }[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m        if (rs.getAvailableWithoutFetching > 0) {[0m
[0m[[0m[0mdebug[0m] [0m[0m          if (isAvailable(out)) {[0m
[0m[[0m[0mdebug[0m] [0m[0m            push(out, rs.one())[0m
[0m[[0m[0mdebug[0m] [0m[0m          }[0m
[0m[[0m[0mdebug[0m] [0m[0m        } else {[0m
[0m[[0m[0mdebug[0m] [0m[0m          completeStage()[0m
[0m[[0m[0mdebug[0m] [0m[0m        }[0m
[0m[[0m[0mdebug[0m] [0m[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m      case Failure(failure) => failStage(failure)[0m
[0m[[0m[0mdebug[0m] [0m[0m    }[0m
[0m[[0m[0mdebug[0m] [0m[0m  }[0m
[0m[[0m[0mdebug[0m] [0m[0m}[0m
[0m[[0m[0mdebug[0m] [0m[0mModified text of file is:[0m
[0m[[0m[0mdebug[0m] [0m[0mNone[0m
